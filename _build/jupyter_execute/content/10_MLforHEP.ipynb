{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89189748",
   "metadata": {},
   "source": [
    "# ML for HEP\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/chattopadhyayA/ml_pursue2025/blob/master/content/10_MLforHEP.ipynb\" target=\"_blank\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcda9b3",
   "metadata": {},
   "source": [
    "Through all the other course of this workshop, you are already familiar with the scale of data that physicists have to handle.On top of that, even to know that the full experiment is going smoothly, one have to basically look at thousands of histograms per minute to draw any conclusion. ML would be helpful in both minimising the human effort, quick data mining as well as hidden feature extractions as well. \n",
    "\n",
    "\n",
    "Because of these huge amount of data, any full scale demonstration of ML model in HEP is not possible. One should remember that as of now the goal of ML in physics is not to replace the physics simulation but to aid it. Imagine how easy would it be if one can automate Data Quality Monitoring (DQM) through ML to get some burden away from the shifters. The goal is always to help, but not to replace physics. Any ML algorithm that might help particle physics, should itself obey the laws of physics, albeit in some obscure way. \n",
    "\n",
    "\n",
    "For example jet-data can be transformed as images. Now the question is, if there is any pattern to it or not. This images are produced from JetNet dataset, which is synthetically simulated jet data. You can try and analyze the images to tag which jets are from what particle\n",
    "\n",
    "\n",
    "\n",
    "![alt text](images/jetnet2.png \"Title\")\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "- The goal of particle physics is to understand the nature, towards that we can use ML in several possible places\n",
    "\n",
    "\n",
    "![alt text](images/pphysics.png \"Title\")\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b1db91",
   "metadata": {},
   "source": [
    "Towards that our asignment would be to do Higgs classification.\n",
    "\n",
    "**Background:** High-energy collisions at the Large Hadron Collider (LHC) produce particles that interact with particle detectors. One important task is to classify different types of collisions based on their physics content, allowing physicists to find patterns in the data and to potentially unravel new discoveries.\n",
    "\n",
    "**Problem statement:** The discovery of the Higgs boson by CMS and ATLAS Collaborations was announced at CERN in 2012. In this work, we focus on the potential of Machine Learning and Deep Learning in detecting potential Higgs signal from one of the background processes that mimics it.\n",
    "\n",
    "**Dataset:** The dataset is made available by the Center for Machine Learning and Intelligent Systems at University of California, Irvine. The dataset can be found on the [UCI Machine learning Repository](https://archive.ics.uci.edu/ml/datasets/HIGGS)\n",
    "\n",
    "**Description:** The dataset consists of a total of 11 million labeled samples of Higgs vs background events produced by Monte Carlo simulations. Each sample consists of 28 features. The first 21 features are kinematic properties measured at the level of the detectors. The last seven are functions of the first 21."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47e751d",
   "metadata": {},
   "source": [
    "**Steps to load the training dataset**\n",
    "1. Download the dataset from the UCI website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32746dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b6eef1",
   "metadata": {},
   "source": [
    "2. Unzip the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4998b1",
   "metadata": {},
   "outputs": [],
   "source": [
    " !gzip -d HIGGS.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba25b526",
   "metadata": {},
   "source": [
    "3. Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11647c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import h5py\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60682ac4",
   "metadata": {},
   "source": [
    "**Load the file using pandas library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a68bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('./HIGGS.csv', header=None)\n",
    "## print the first 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95a115b",
   "metadata": {},
   "source": [
    "The first column is the class label (1 for signal, 0 for background), followed by the 28 features (21 low-level features then 7 high-level features): lepton pT, lepton eta, lepton phi, missing energy magnitude, missing energy phi, jet 1 pt, jet 1 eta, jet 1 phi, jet 1 b-tag, jet 2 pt, jet 2 eta, jet 2 phi, jet 2 b-tag, jet 3 pt, jet 3 eta, jet 3 phi, jet 3 b-tag, jet 4 pt, jet 4 eta, jet 4 phi, jet 4 b-tag, m_jj, m_jjj, m_lv, m_jlv, m_bb, m_wbb, m_wwbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c5fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## change the column numbers to column names\n",
    "data.columns = ['target',\n",
    "              'lep_pT',\n",
    "              'lep_eta',\n",
    "              'lep_phi',\n",
    "              'missE',\n",
    "              'missphi',\n",
    "              'jet1_pt',\n",
    "              'jet1_eta',\n",
    "              'jet_1_phi',\n",
    "              'jet_1_b_tag',\n",
    "              'jet_2_pt',\n",
    "              'jet_2_eta',\n",
    "              'jet_2_phi',\n",
    "              'jet_2_b_tag',\n",
    "              'jet_3_pt',\n",
    "              'jet_3_eta',\n",
    "              'jet_3_phi',\n",
    "              'jet_3_b_tag',\n",
    "              'jet_4_pt',\n",
    "              'jet_4_eta',\n",
    "              'jet_4_phi',\n",
    "              'jet_4_b_tag',\n",
    "              'm_jj',\n",
    "              'm_jjj',\n",
    "              'm_lv',\n",
    "              'm_jlv',\n",
    "              'm_bb',\n",
    "              'm_wbb',\n",
    "              'm_wwbb']\n",
    "\n",
    "## print the first 5 rows (including the column names)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb46b9d2",
   "metadata": {},
   "source": [
    "Assign first column 0 to class labels (labeled 1 for signal, 0 for background)  and all others to feature matrix X.\n",
    "\n",
    "In this example, for the sake of fast checking, we use 1000 samples. To train on the entire dataset, proceed with uncommenting the lines below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d3d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:1000,1:]#data.iloc[:,1:]\n",
    "y=data.iloc[:1000,0]#data.iloc[:,0]\n",
    "\n",
    "X_train1, X_val, y_train1, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train1, y_train1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa65887c",
   "metadata": {},
   "source": [
    "**Visualize your data - One histogram per feature column**\n",
    "\n",
    "Detailed information on what each feature column is can be found in *Attribute Information* section on the [UCI Machine learning Repositery](https://archive.ics.uci.edu/ml/datasets/HIGGS). For further information, refer to the [paper](https://www.nature.com/articles/ncomms5308) by Baldi et. al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a8156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(len(X_train.columns)//3, 3, figsize=(12, 48))\n",
    "\n",
    "i = 0\n",
    "for triaxis in axes:\n",
    "    for axis in triaxis:\n",
    "        X_train.hist(column = X_train.columns[i], bins = 100, ax=axis)\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415011e5",
   "metadata": {},
   "source": [
    "** Proceed with Decision tree and ML **\n",
    "\n",
    "The answers will be given here afterwards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e9dcf3",
   "metadata": {},
   "source": [
    "\n",
    "```{figure} images/thanks.png\n",
    "---\n",
    "height: 300px\n",
    "name:   thanks\n",
    "align:  center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0842219",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8b20cff",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jarvis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}